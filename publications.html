<!DOCTYPE html>
<html>
    <head>
        <title>publications - Mirco Kocher</title>
        <link rel="stylesheet" type="text/css" href="style.css">
        <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
        <link rel="icon" type="image/png" href="/favicon/favicon-32x32.png" sizes="32x32">
        <link rel="icon" type="image/png" href="/favicon/favicon-16x16.png" sizes="16x16">
        <link rel="manifest" href="/favicon/manifest.json">
        <link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#5bbad5">
        <link rel="shortcut icon" href="/favicon/favicon.ico">
        <meta name="msapplication-config" content="/favicon/browserconfig.xml">
        <meta name="theme-color" content="#ffffff">
        <script src="csi.js"></script>
    </head>
    <body>
        <div class="navbar">
            <ul>
                <li><a class="navbar-home" href="http://mirc0crim.github.io">Mirco</a></li>
                <li><a class="navbar-nav" href="http://mirc0crim.github.io">Home</a></li>
                <li><a class="navbar-now" href="http://mirc0crim.github.io/publications.html">Publications</a></li>
                <li><a class="navbar-nav" href="http://mirc0crim.github.io/teaching.html">Teaching</a></li>
            </ul>
        </div>
        <div class="container">
            <div class="main">
                <h1>bibliography</h1>
                <p>
                    You can hover over an entry to read the abstract. </br>
                    There are &#9632; journal articles, &#9679; conference proceedings, and &#9675; working notes.
                </p>
                <p>
                    <b>2017</b> 
                </p>
                <ul>
                    </li>
                    <li class="tooltip" type="square">
                        <b>Distance Measures in Author Profiling</b>.<br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        <i>Information Processing and Management</i>, 53(5), September 2017, 1103-1119.
                        <a target="_blank" href="http://www.sciencedirect.com/science/article/pii/S0306457316306495">Paper</a><br/>
                        <span>
                            Determining some demographics about the author of a document (e.g., gender, age) has attracted many studies during the last decade.
                            To determine the targeted category, different distance measures have been suggested without one approach clearly dominating all others.
                            In this paper, 24 distance measures are studied, extracted from five general families of functions.
                            Moreover, six theoretical properties are presented and we show that the Tanimoto or Matusita distance measures respect all proposed properties.
                            To complement this analysis, 13 test collections extracted from the last CLEF evaluation campaigns are employed to evaluate empirically the effectiveness of these distance measures.
                            The empirical evaluations indicate that the Canberra or Clark distance measures tend to produce better effectiveness, at least in the context of an author profiling task.
                        </span>
                    </li>
                    <li class="tooltip" type="square">
                        <b>Distributed Language Representation for Authorship Attribution</b>.<br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        <i>Digital Scholarship in the Humanities</i>. (to appear)<br/>
                        <a target="_blank" href="http://dx.doi.org/10.1093/llc/fqx046">Paper</a><br/>
                        <span>
                            Distributed language representation (deep learning) has been applied successfully in different applications in natural language processing (NLP).
                            Using this model, we propose and implement two new authorship attribution classifiers.
                            In this perspective, a vector-space representation can be generated for each author or disputed text according to words and their nearby context.
                            To determine the authorship of a disputed text, the cosine similarity between vector representations can be applied.
                            The proposed strategies can be adapted without any difficulty to different languages (such as English and Italian) or genres (essays, political speeches, and newspaper articles).
                            Evaluations using the k-nearest neighbors and based on four test collections (the Federalist Papers, the State of the Union addresses, the Glasgow Herald, and La Stampa newspapers) indicate that the distributed language representation preforms well, providing sometimes better effectiveness than state-of-the-art methods such as k-NN, NSC, chi-square, Delta, LDA (latent Dirichlet allocation), or multi-layer perceptron classifier.
                        </span>
                    </li>
                    <li class="tooltip" type="square">
                        <b>A Simple and Efficient Algorithm for Authorship Verification</b>.<br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        <i>Journal of the American Society for Information Science and Technology</i>, 68(1), 2017, 259-269.
                        <a target="_blank" href="http://onlinelibrary.wiley.com/doi/10.1002/asi.23648/epdf">Paper</a><br/>
                        <span>
                            This paper describes and evaluates an unsupervised and effective authorship verification model.
                            The suggested strategy can be adapted without any problem to different Indo-European languages (such as Dutch, English, Spanish, and Greek) or genres (essay, novel, review, and newspaper article).
                            Applying a simple distance measure and a set of impostors, we can determine whether or not the disputed text was written by the proposed author.
                            Moreover, based on a simple rule, we can define when there is enough evidence to propose an answer or when the attribution scheme is unable to take a decision with a high degree of certainty.
                            Evaluations based on six test collections (PAN CLEF 2014 evaluation campaign) indicate that our approach usually appears in the top three best verification systems, and on an aggregate measure, presents the best performance.
                        </span>
                    </li>
                    <li class="tooltip" type="disc">
                        <b>Author Clustering with an Adaptive Threshold</b><br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        In Jones, G. J. F., Lawless, S., Gonzalo, J., Kelly, L., Goeuriot, L., Thomas M., Cappellato, L., &amp; Ferro, N. (Eds), <i>Experimental IR Meets Multilinguality, Multimodality, and Interaction, 8th International Conference of the CLEF Association, CLEF 2017, Dublin, Ireland, September 11-14, 2017, Proceedings</i>. (to appear)<br/>
                        <span>
                            This paper describes and evaluates an unsupervised author clustering model called SPATIUM. 
                            The proposed strategy can be adapted without any difficulty to different natural languages (such as Dutch, English, and Greek) and it can be applied to different text genres (newspaper articles, reviews, excerpts of novels, etc.).
                            As features, we suggest using the m most frequent terms of each text (isolated words and punctuation symbols with m set to at most 200).
                            Applying a distance measure, we define whether there is enough evidence that two texts were written by the same author.
                            The evaluations are based on six test collections (PAN AUTHOR CLUSTERING task at CLEF 2016).
                            A more detailed analysis shows the strengths of our approach but also indicates the problems and provides reasons for some of the failures of the SPATIUM model.
                        </span>
                    </li>
                    <li class="tooltip" type="disc">
                        <b>Author Clustering Using SPATIUM</b><br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        <i>Short Paper, JCDL 2017, Toronto, Canada, June 19-23, 2017</i>. ACM/IEEE, 265-268.
                        <a target="_blank" href="https://doi.org/10.1109/JCDL.2017.7991586">Paper</a><br/>
                        <span>
                            This paper presents the author clustering problem and compares it to related authorship attribution questions.
                            The proposed model is based on a distance measure called SPATIUM derived from the Canberra measure (weighted version of L1 norm).
                            The selected features consist of the 200 most frequent words and punctuation symbols.
                            An evaluation methodology is presented and the test collections are extracted from the PAN CLEF 2016 evaluation campaign.
                            In addition to those, we also consider two additional corpora reflecting the literature domain more closely.
                            Based on four different languages, the evaluation measures demonstrate a high precision and high F1 values for all 20 test collections.
                            A more detailed analysis provides reasons explaining some of the failures of the SPATIUM model.
                        </span>
                    </li>
                    <li class="tooltip" type="disc">
                        <b>Regroupement d'auteurs: Qui a &eacute;crit cet ensemble de romans?</b><br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        In Nie, J.Y. and Lamprier, S. (Eds), <i>Proceeding CORIA 2017, Marseille, France, March 29-31, 2017</i>, ARIA, 311-326.
                        <a target="_blank" href="http://www.asso-aria.org/coria/2017/3.pdf">Paper</a><br/>
                        <span>
                            In French.
                            This paper describes the author clustering problem where, based on a set of n texts, the number k of distinct authors must be determined and the texts must be regrouped into k classes according to their author.
                            Using two test collections, one written in French, the second in English, different distance measures are described and evaluated.
                            To define the needed features, the m most frequent words (e.g., m between 50 to 300) or the m letters and bigrams of letters have been used.
                            Our experiments show that word-based representations offer usually the best performance.
                            Using the cosine distance function does not produce a better F1 value compared to functions based on the L1 norm (e.g., Canberra).
                            However, the best distance measure for all cases cannot be defined precisely.
                            Applying a bootstrap approach, we show that the performance measures own a relatively large variability.
                            Finally, a deeper analysis indicates the difficulties and reasons explaining incorrect assignments.
                        </span>
                    <li class="tooltip" type="circle">
                        <b>UniNE at CLEF 2017: Author Clustering: Notebook for PAN at CLEF 2017</b><br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        In Capellato, L., Ferro, N., Goeuriot, L., &amp; Mandl, T. (Eds), <i>CLEF 2017 Labs Working Notes, Dublin, Ireland, September 11-14, 2017</i>, Aachen: CEUR.
                        <a target="_blank" href="http://ceur-ws.org/Vol-1866/paper_55.pdf">Paper</a>
                        <br/>
                        <span>
                            This paper describes and evaluates an effective unsupervised author clustering and authorship linking model.
                            The suggested strategy can be adapted without any difficulty to different languages (such as Dutch, English, and Greek) in different text genres (e.g., newspaper articles and reviews).
                            As features, we suggest using the m most frequent terms (isolated words and punctuation symbols) or the m most frequent character n-grams of each text.
                            Applying a simple distance measure, we determine whether there is enough indication that two texts were written by the same author.
                            The evaluations are based on 60 training and 120 test problems (PAN Author Clustering task at CLEF 2017).
                            Using the most frequent terms results in a higher clustering precision, while using the most frequent character n-grams of letters gives a higher clustering recall.
                            An analysis to assess the variability of the performance measures indicates that we have a system working stable independent of the underlying text collection and that our parameter choices did not over-fit to the training data.
                        </span>
                    </li>
                    <li class="tooltip" type="circle">
                        <b>UniNE at CLEF 2017: Author Profiling Reasoning: Notebook for PAN at CLEF 2017</b><br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        In Capellato, L., Ferro, N., Goeuriot, L., &amp; Mandl, T. (Eds), <i>CLEF 2017 Labs Working Notes, Dublin, Ireland, September 11-14, 2017</i>, Aachen: CEUR.
                        <a target="_blank" href="http://ceur-ws.org/Vol-1866/paper_56.pdf">Paper</a>
                        <br/>
                        <span>
                            This paper describes and evaluates a supervised author profiling model.
                            The suggested strategy can be adapted without any problem to various languages (such as Arabic, English, Spanish, and Portuguese).
                            As features, we suggest using the m most frequent terms of the query text (isolated words and punctuation symbols with m at most 200).
                            Applying a simple distance measure and looking at the nearest text profiles, we can determine the gender (with the nominal values “male” or “female”) and the language variety (e.g., in Spanish the nominal values “Argentina”, “Chile”, “Colombia”, “Mexico”, “Peru”, “Spain”, or “Venezuela”).
                            The training and test data is available for Twitter tweets (PAN Author Profiling task at CLEF 2017).
                            An analysis of the top ranked terms from a feature selection method allows a better understanding of the proposed assignments and presents typical writing styles for each category.
                        </span>
                    </li>
                </ul>
                <p>
                    <b>2016</b>
                </p>
                <ul>
                    <li class="tooltip" type="circle">
                        <b>UniNE at CLEF 2016 Author Clustering: Notebook for PAN at CLEF 2016</b>.<br/>
                        Mirco Kocher.<br/>
                        In Balog, K., Capellato, L., Ferro, N., &amp; Macdonald, C. (Eds), <i>CLEF 2016 Labs Working Notes, &Eacute;vora, Portugal, September 5-8, 2016</i>, Aachen: CEUR.
                        <a target="_blank" href="http://ceur-ws.org/Vol-1609/16090895.pdf">Paper</a>
                        <a target="_blank" href="http://www.uni-weimar.de/medien/webis/events/pan-16/pan16-talks/pan16-author-identification/kocher16a-poster.pdf">Poster</a>
                        <a target="_blank" href="http://www.uni-weimar.de/medien/webis/events/pan-16/pan16-talks/pan16-author-identification/kocher16a-slides.pdf">Slides</a>
                        <br/>
                        <span>
                            This notebook describes and evaluates an effective unsupervised author clustering model.
                            The suggested strategy can be adapted without any problem to different languages (such as Dutch, English, and Greek) in different genres (newspaper articles and reviews).
                            Applying a simple distance measure, we determine whether there is enough indication that two texts were written by the same author.
                            The proposed clustering performs very well (rank 2 over all test collections) in a comparison of 8 approaches.
                        </span>
                    </li>
                    <li class="tooltip" type="circle">
                        <b>UniNE at CLEF 2016 Author Profiling: Notebook for PAN at CLEF 2016</b>.<br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        In Balog, K., Capellato, L., Ferro, N., &amp; Macdonald, C. (Eds), <i>CLEF 2016 Labs Working Notes, &Eacute;vora, Portugal, September 5-8, 2016</i>, Aachen: CEUR.
                        <a target="_blank" href="http://ceur-ws.org/Vol-1609/16090903.pdf">Paper</a>
                        <a target="_blank" href="http://www.uni-weimar.de/medien/webis/events/pan-16/pan16-talks/pan16-author-profiling/kocher16b-poster.pdf">Poster</a>
                        <br/>
                        <span>
                            This notebook describes and evaluates a cross-genre author profiling model.
                            The suggested strategy can be adapted without any problem to different Indo-European languages.
                            Applying a simple distance measure and looking at the five nearest neighbors, we can determine the gender (male or female) and the age group (18-24 | 25-34 | 35-49 | 50-64 | &gt;65).
                            The proposed cross-genre profiling performs acceptable (rank 14 over all test collections) in a comparison of 23 approaches.
                        </span>
                    </li>
                </ul>
                <p>
                    <b>2015</b>
                </p>
                <ul>
                    <li class="tooltip" type="circle">
                        <b>UniNE at CLEF 2015 Author Identification: Notebook for PAN at CLEF 2015</b>.<br/>
                        Mirco Kocher &amp; Jacques Savoy.<br/>
                        In Capellato, L., Ferro, N., Jones, F. J. F., &amp; Juan, E. S. (Eds), <i>CLEF 2015 Labs Working Notes, Toulouse, France, September 8-11, 2015</i>, Aachen: CEUR.
                        <a target="_blank" href="http://ceur-ws.org/Vol-1391/28-CR.pdf">Paper</a>
                        <a target="_blank" href="http://www.uni-weimar.de/medien/webis/events/pan-15/pan15-talks/pan15-authorship-verification/kocher15b-poster.pdf">Poster</a>
                        <br/>
                        <span>
                            This notebook presents and evaluates an unsupervised authorship verification model.
                            The suggested strategy can be adapted without any problem to different languages with their genre and topic differ significantly.
                            Applying a simple distance measure and a set of impostors, we determine whether or not the disputed text was written by the proposed author.
                            The proposed identification usually performs well (rank 8 over all test collections) in a comparison of 19 approaches.
                        </span>
                    </li>
                    <li class="tooltip" type="circle">
                        <b>UniNE at CLEF 2015 Author Profiling: Notebook for PAN at CLEF 2015</b>.<br/>
                        Mirco Kocher.<br/>
                        In Capellato, L., Ferro, N., Jones, F. J. F., &amp; Juan, E. S. (Eds), <i>CLEF 2015 Labs Working Notes, Toulouse, France, September 8-11, 2015</i>, Aachen: CEUR.
                        <a target="_blank" href="http://ceur-ws.org/Vol-1391/27-CR.pdf">Paper</a>
                        <a target="_blank" href="http://www.uni-weimar.de/medien/webis/events/pan-15/pan15-talks/pan15-author-profiling/kocher15a-poster.pdf">Poster</a>
                        <br/>
                        <span>
                            This notebook presents and evaluates an effective author profiling model.
                            The suggested strategy can be adapted without any problem to different languages in Twitter tweets.
                            We can determine the gender (male and female), the age group (18-24 | 25-34 | 35-49 | &gt;50), and the Big Five personality traits (each on an interval scale containing eleven items).
                            The proposed profiling performs well (rank 4 over all test collections) in a comparison of 23 approaches.
                        </span>
                    </li>
                </ul>
            </div>
            <div data-include="me-sidebar.html"></div>
        </div>
        <div class="footer">
            Last updated: 2017/07/26
        </div>
    </body>
</html>
